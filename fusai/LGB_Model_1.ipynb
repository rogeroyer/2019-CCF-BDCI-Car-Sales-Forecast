{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初赛\n",
    "df_sale_chusai = pd.read_csv('../chusai/data/train_sales_data.csv')\n",
    "df_search_chusai = pd.read_csv('../chusai/data/train_search_data.csv')\n",
    "df_user_chusai = pd.read_csv('../chusai/data/train_user_reply_data.csv')\n",
    "df_eval_chusai = pd.read_csv('../chusai/data/evaluation_public.csv')\n",
    "\n",
    "sale_chusai = df_sale_chusai.copy()\n",
    "search_chusai = df_search_chusai.copy()\n",
    "user_chusai = df_user_chusai.copy()\n",
    "evaluation_chusai = df_eval_chusai.copy()\n",
    "\n",
    "data_chusai = pd.merge(sale_chusai, search_chusai, how='left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "\n",
    "# 复赛\n",
    "df_sale = pd.read_csv('./data/train_sales_data.csv')\n",
    "df_search = pd.read_csv('./data/train_search_data.csv')\n",
    "df_user = pd.read_csv('./data/train_user_reply_data.csv')\n",
    "df_eval = pd.read_csv('./data/evaluation_public.csv')\n",
    "\n",
    "sale = df_sale.copy()\n",
    "search = df_search.copy()\n",
    "user = df_user.copy()\n",
    "evaluation = df_eval.copy()\n",
    "\n",
    "data = pd.merge(sale, search, how='left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "# data = pd.merge(data, user, how='left', on=['model', 'regYear', 'regMonth'])\n",
    "\n",
    "data_fusai = data[31680:]\n",
    "evaluation_fusai = evaluation[5280:]\n",
    "\n",
    "def offline_validation(data, pred='pred', label='label', group='model'):\n",
    "    data['pred'] = data['pred'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({pred:list, label:[list, 'mean']}).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(mean_squared_error(raw[0], raw[1]) ** 0.5 / raw[2])\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "#     return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# 去除无用特征\n",
    "data_fusai.drop(['adcode'], axis=1, inplace=True)\n",
    "evaluation_fusai.drop(['forecastVolum', 'adcode'], axis=1, inplace=True)\n",
    "\n",
    "# 给测试集拼接 bodyType\n",
    "temp = data_fusai[['province', 'model', 'bodyType']].drop_duplicates()\n",
    "evaluation_fusai = evaluation_fusai.merge(temp, how='left', on=['province', 'model'])\n",
    "\n",
    "# 编码\n",
    "le1 = LabelEncoder()\n",
    "data_fusai['province'] = le1.fit_transform(data_fusai['province'])\n",
    "evaluation_fusai['province'] = le1.fit_transform(evaluation_fusai['province'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "data_fusai['model'] = le2.fit_transform(data_fusai['model'])\n",
    "evaluation_fusai['model'] = le2.fit_transform(evaluation_fusai['model'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "data_fusai['bodyType'] = le3.fit_transform(data_fusai['bodyType'])\n",
    "evaluation_fusai['bodyType'] = le3.fit_transform(evaluation_fusai['bodyType'])\n",
    "\n",
    "# 重新编码月份\n",
    "data_fusai['regMonth'] = data_fusai.apply(lambda row: row['regMonth'] + (row['regYear']-2016)*12, axis=1).map(int)\n",
    "\n",
    "# 对salesVolume做log变换\n",
    "data_fusai['salesVolume'] = np.log1p(data_fusai['salesVolume'])\n",
    "# 修正popularity\n",
    "# data_fusai.loc[data_fusai['popularity']>80000, 'popularity'] = 30000\n",
    "# data_fusai['popularity'] = np.log1p(data_fusai['popularity'])\n",
    "\n",
    "\n",
    "dataset_fusai = data_fusai[data_fusai['regYear']==2017]\n",
    "\n",
    "test_fusai = evaluation_fusai.copy()\n",
    "\n",
    "def distance_to_springfestival(row):\n",
    "    regYear = row['regYear']\n",
    "    regMonth = row['regMonth']\n",
    "     # 16春节：2月，17春节：1月，18春节：2月\n",
    "    if regYear==2016:   \n",
    "        if regMonth!=12:\n",
    "            return regMonth-2\n",
    "        else:\n",
    "            return -1\n",
    "    elif regYear==2017:\n",
    "        return regMonth-13\n",
    "    else:\n",
    "        return regMonth-26\n",
    "    \n",
    "def tongji(row, mt_num=1, which='sale', method='mean'):\n",
    "    mt = []\n",
    "    for i in range(mt_num):\n",
    "        mt.append(row['mt' + str(i+1) + '_' + which])\n",
    "#     mt.append(row['mt2_' + which])\n",
    "#     mt.append(row['mt3_' + which])\n",
    "#     mt.append(row['mt4_' + which])\n",
    "#     mt.append(row['mt5_' + which])\n",
    "#     mt.append(row['mt6_' + which])\n",
    "    ls = mt[:mt_num]\n",
    "    \n",
    "    if method=='mean':\n",
    "        return np.mean(ls)\n",
    "    elif method=='max':\n",
    "        return np.max(ls)\n",
    "    elif method=='min':\n",
    "        return np.min(ls)\n",
    "    elif method=='median':\n",
    "        return np.median(ls)\n",
    "    elif method=='var':\n",
    "        return np.var(ls)\n",
    "    elif method=='std':\n",
    "        return np.median(ls)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bulid_model(X_train, y_train, X_valid=None, y_valid=None, cate_feat=None):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "#     if X_valid is not None:\n",
    "#     lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'mse',\n",
    "        'metric': 'mse',       # 'l2', 'binary_logloss', 'auc'\n",
    "        'learning_rate': 0.05,\n",
    "        'boost_from_average': False,\n",
    "    #     'min_data_in_leaf':50,\n",
    "    #     'num_leaves': 30,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "    #     'subsample_freq': 5,\n",
    "        'colsample_bytree': 0.8,\n",
    "    #     'bagging_freq': 5,\n",
    "        'seed': 666,\n",
    "        'nthread': -1,\n",
    "        'verbose': 1,\n",
    "    }\n",
    "    lgb_model = lgb.train(params, lgb_train, num_boost_round=3000, categorical_feature=cate_feat)\n",
    "    return lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(data, history, gap=1):\n",
    "    \n",
    "    dataset = data.copy()\n",
    "    hist = history.copy()\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    hist.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print('Before data shape: ', dataset.shape)\n",
    "    print('-' * 30)\n",
    "    \n",
    "    '''历史特征'''\n",
    "    # sale\n",
    "    last_mt_sales, last_y_pops = [], []\n",
    "    prev_mt1_sales, prev_mt2_sales, prev_mt3_sales, prev_mt4_sales, prev_mt5_sales, prev_mt6_sales = [], [], [], [], [], []\n",
    "    prev_mt7_sales, prev_mt8_sales, prev_mt9_sales, prev_mt10_sales, prev_mt11_sales, prev_mt12_sales = [], [], [], [], [], []\n",
    "    \n",
    "    last_mt_pops, last_y_pops = [], []\n",
    "    prev_mt1_pops, prev_mt2_pops, prev_mt3_pops, prev_mt4_pops, prev_mt5_pops, prev_mt6_pops = [], [], [], [], [], []\n",
    "    prev_mt7_pops, prev_mt8_pops, prev_mt9_pops, prev_mt10_pops, prev_mt11_pops, prev_mt12_pops = [], [], [], [], [], []\n",
    "    \n",
    "    for row in dataset.itertuples():\n",
    "#         row = dataset[i:i+1][['province', 'model', 'regYear', 'regMonth']]\n",
    "#         values = row.values.tolist()[0]\n",
    "        province, model, regYear, regMonth = row.province, row.model, row.regYear, row.regMonth\n",
    "        # 去年同月\n",
    "        last_mt_sale = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-12)]['salesVolume'].values[0]\n",
    "        last_mt_sales.append(last_mt_sale)\n",
    "        last_mt_pop = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-12)]['popularity'].values[0]\n",
    "        last_mt_pops.append(last_mt_pop)\n",
    "        # 前几个月sale\n",
    "        prev_sale1 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-1)]['salesVolume'].values[0]\n",
    "        prev_mt1_sales.append(prev_sale1)\n",
    "        prev_sale2 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-2)]['salesVolume'].values[0]\n",
    "        prev_mt2_sales.append(prev_sale2)\n",
    "        prev_sale3 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-3)]['salesVolume'].values[0]\n",
    "        prev_mt3_sales.append(prev_sale3)\n",
    "        prev_sale4 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-4)]['salesVolume'].values[0]\n",
    "        prev_mt4_sales.append(prev_sale4)\n",
    "        prev_sale5 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-5)]['salesVolume'].values[0]\n",
    "        prev_mt5_sales.append(prev_sale5)\n",
    "        prev_sale6 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-6)]['salesVolume'].values[0]\n",
    "        prev_mt6_sales.append(prev_sale6)\n",
    "        prev_sale7 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-7)]['salesVolume'].values[0]\n",
    "        prev_mt7_sales.append(prev_sale7)\n",
    "        prev_sale8 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-8)]['salesVolume'].values[0]\n",
    "        prev_mt8_sales.append(prev_sale8)\n",
    "        prev_sale9 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-9)]['salesVolume'].values[0]\n",
    "        prev_mt9_sales.append(prev_sale9)\n",
    "        prev_sale10 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-10)]['salesVolume'].values[0]\n",
    "        prev_mt10_sales.append(prev_sale10)\n",
    "        prev_sale11 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-11)]['salesVolume'].values[0]\n",
    "        prev_mt11_sales.append(prev_sale11)\n",
    "        # 前几个月pop\n",
    "        prev_pop1 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-1)]['popularity'].values[0]\n",
    "        prev_mt1_pops.append(prev_pop1)\n",
    "        prev_pop2 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-2)]['popularity'].values[0]\n",
    "        prev_mt2_pops.append(prev_pop2)\n",
    "        prev_pop3 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-3)]['popularity'].values[0]\n",
    "        prev_mt3_pops.append(prev_pop3)\n",
    "        prev_pop4 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-4)]['popularity'].values[0]\n",
    "        prev_mt4_pops.append(prev_pop4)\n",
    "        prev_pop5 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-5)]['popularity'].values[0]\n",
    "        prev_mt5_pops.append(prev_pop5)\n",
    "        prev_pop6 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-6)]['popularity'].values[0]\n",
    "        prev_mt6_pops.append(prev_pop6)\n",
    "        prev_pop7 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-7)]['popularity'].values[0]\n",
    "        prev_mt7_pops.append(prev_pop7)\n",
    "        prev_pop8 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-8)]['popularity'].values[0]\n",
    "        prev_mt8_pops.append(prev_pop8)\n",
    "        prev_pop9 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-9)]['popularity'].values[0]\n",
    "        prev_mt9_pops.append(prev_pop9)\n",
    "        prev_pop10 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-10)]['popularity'].values[0]\n",
    "        prev_mt10_pops.append(prev_pop10)\n",
    "        prev_pop11 = hist[(hist['province']==province) & (hist['model']==model) & (hist['regMonth']==regMonth-11)]['popularity'].values[0]\n",
    "        prev_mt11_pops.append(prev_pop11)\n",
    "        \n",
    "    temp = pd.DataFrame()\n",
    "    temp['last_sale'] = last_mt_sales\n",
    "    temp['mt1_sale'] = prev_mt1_sales\n",
    "    temp['mt2_sale'] = prev_mt2_sales\n",
    "    temp['mt3_sale'] = prev_mt3_sales\n",
    "    temp['mt4_sale'] = prev_mt4_sales\n",
    "    temp['mt5_sale'] = prev_mt5_sales\n",
    "    temp['mt6_sale'] = prev_mt6_sales\n",
    "    temp['mt7_sale'] = prev_mt7_sales\n",
    "    temp['mt8_sale'] = prev_mt8_sales\n",
    "    temp['mt9_sale'] = prev_mt9_sales\n",
    "    temp['mt10_sale'] = prev_mt10_sales\n",
    "    temp['mt11_sale'] = prev_mt11_sales\n",
    "    temp['last_pop'] = last_mt_pops\n",
    "    temp['mt1_pop'] = prev_mt1_pops\n",
    "    temp['mt2_pop'] = prev_mt2_pops\n",
    "    temp['mt3_pop'] = prev_mt3_pops\n",
    "    temp['mt4_pop'] = prev_mt4_pops\n",
    "    temp['mt5_pop'] = prev_mt5_pops\n",
    "    temp['mt6_pop'] = prev_mt6_pops\n",
    "    temp['mt7_pop'] = prev_mt7_pops\n",
    "    temp['mt8_pop'] = prev_mt8_pops\n",
    "    temp['mt9_pop'] = prev_mt9_pops\n",
    "    temp['mt10_pop'] = prev_mt10_pops\n",
    "    temp['mt11_pop'] = prev_mt11_pops\n",
    "    dataset = pd.concat([dataset, temp], axis=1)\n",
    "\n",
    "    # 直接差分\n",
    "    dataset['mt1_2_sale'] = dataset['mt1_sale'] - dataset['mt2_sale']\n",
    "    dataset['mt2_3_sale'] = dataset['mt2_sale'] - dataset['mt3_sale']\n",
    "    dataset['mt3_4_sale'] = dataset['mt3_sale'] - dataset['mt4_sale']\n",
    "    dataset['mt4_5_sale'] = dataset['mt4_sale'] - dataset['mt5_sale']\n",
    "    dataset['mt5_6_sale'] = dataset['mt5_sale'] - dataset['mt6_sale']\n",
    "    dataset['mt6_7_sale'] = dataset['mt6_sale'] - dataset['mt7_sale']\n",
    "    dataset['mt7_8_sale'] = dataset['mt7_sale'] - dataset['mt8_sale']\n",
    "    dataset['mt8_9_sale'] = dataset['mt8_sale'] - dataset['mt9_sale']\n",
    "    dataset['mt9_10_sale'] = dataset['mt9_sale'] - dataset['mt10_sale']\n",
    "    dataset['mt10_11_sale'] = dataset['mt10_sale'] - dataset['mt11_sale']\n",
    "    dataset['mt11_12_sale'] = dataset['mt11_sale'] - dataset['last_sale']\n",
    "    dataset['mt_tongbi_sale'] = dataset['mt1_sale'] - dataset['last_sale']\n",
    "    dataset['mt1_2_sale_rate'] = dataset['mt1_2_sale'] / dataset['mt1_sale']\n",
    "    dataset['mt2_3_sale_rate'] = dataset['mt2_3_sale'] / dataset['mt2_sale']\n",
    "    dataset['mt3_4_sale_rate'] = dataset['mt3_4_sale'] / dataset['mt3_sale']\n",
    "    dataset['mt4_5_sale_rate'] = dataset['mt4_5_sale'] / dataset['mt4_sale']\n",
    "    dataset['mt5_6_sale_rate'] = dataset['mt5_6_sale'] / dataset['mt5_sale']\n",
    "    dataset['mt6_7_sale_rate'] = dataset['mt6_7_sale'] / dataset['mt6_sale']\n",
    "    dataset['mt7_8_sale_rate'] = dataset['mt7_8_sale'] / dataset['mt7_sale']\n",
    "    dataset['mt8_9_sale_rate'] = dataset['mt8_9_sale'] / dataset['mt8_sale']\n",
    "    dataset['mt9_10_sale_rate'] = dataset['mt9_10_sale'] / dataset['mt9_sale']\n",
    "    dataset['mt10_11_sale_rate'] = dataset['mt10_11_sale'] / dataset['mt10_sale']\n",
    "    dataset['mt11_12_sale_rate'] = dataset['mt11_12_sale'] / dataset['mt11_sale']\n",
    "    dataset['mt_tongbi_sale_rate'] = dataset['mt1_sale'] / dataset['last_sale']\n",
    "    \n",
    "    dataset['mt1_2_pop'] = dataset['mt1_pop'] - dataset['mt2_pop']\n",
    "    dataset['mt2_3_pop'] = dataset['mt2_pop'] - dataset['mt3_pop']\n",
    "    dataset['mt3_4_pop'] = dataset['mt3_pop'] - dataset['mt4_pop']\n",
    "    dataset['mt4_5_pop'] = dataset['mt4_pop'] - dataset['mt5_pop']\n",
    "    dataset['mt5_6_pop'] = dataset['mt5_pop'] - dataset['mt6_pop']\n",
    "    dataset['mt6_7_pop'] = dataset['mt6_pop'] - dataset['mt7_pop']\n",
    "    dataset['mt7_8_pop'] = dataset['mt7_pop'] - dataset['mt8_pop']\n",
    "    dataset['mt8_9_pop'] = dataset['mt8_pop'] - dataset['mt9_pop']\n",
    "    dataset['mt9_10_pop'] = dataset['mt9_pop'] - dataset['mt10_pop']\n",
    "    dataset['mt10_11_pop'] = dataset['mt10_pop'] - dataset['mt11_pop']\n",
    "    dataset['mt11_12_pop'] = dataset['mt11_pop'] - dataset['last_pop']\n",
    "    dataset['mt_tongbi_pop'] = dataset['mt1_pop'] - dataset['last_pop']\n",
    "    dataset['mt1_2_pop_rate'] = dataset['mt1_2_pop'] / dataset['mt1_pop']\n",
    "    dataset['mt2_3_pop_rate'] = dataset['mt2_3_pop'] / dataset['mt2_pop']\n",
    "    dataset['mt3_4_pop_rate'] = dataset['mt3_4_pop'] / dataset['mt3_pop']\n",
    "    dataset['mt4_5_pop_rate'] = dataset['mt4_5_pop'] / dataset['mt4_pop']\n",
    "    dataset['mt5_6_pop_rate'] = dataset['mt5_6_pop'] / dataset['mt5_pop']\n",
    "    dataset['mt6_7_pop_rate'] = dataset['mt6_7_pop'] / dataset['mt6_pop']\n",
    "    dataset['mt7_8_pop_rate'] = dataset['mt7_8_pop'] / dataset['mt7_pop']\n",
    "    dataset['mt8_9_pop_rate'] = dataset['mt8_9_pop'] / dataset['mt8_pop']\n",
    "    dataset['mt9_10_pop_rate'] = dataset['mt9_10_pop'] / dataset['mt9_pop']\n",
    "    dataset['mt10_11_pop_rate'] = dataset['mt10_11_pop'] / dataset['mt10_pop']\n",
    "    dataset['mt11_12_pop_rate'] = dataset['mt11_12_pop'] / dataset['last_pop']\n",
    "    dataset['mt_tongbi_pop_rate'] = dataset['mt1_pop'] / dataset['last_pop']\n",
    "    \n",
    "    dataset['distance_to_springfestival'] = dataset.apply(lambda row: distance_to_springfestival(row), axis=1).map(int)\n",
    "\n",
    "    # 6个月 sale\n",
    "    dataset['6mt_mean_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'mean'), axis=1)\n",
    "    dataset['6mt_max_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'max'), axis=1)\n",
    "    dataset['6mt_min_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'min'), axis=1)\n",
    "    dataset['6mt_median_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'median'), axis=1)\n",
    "    dataset['6mt_var_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'var'), axis=1)\n",
    "#     dataset['6mt_std_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'std'), axis=1)\n",
    "#     dataset['6mt_sum_sale'] = dataset.apply(lambda row: tongji(row, 6, 'sale', 'sum'), axis=1)\n",
    "    \n",
    "    dataset['6mt_mean_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'mean'), axis=1)\n",
    "    dataset['6mt_max_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'max'), axis=1)\n",
    "    dataset['6mt_min_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'min'), axis=1)\n",
    "    dataset['6mt_median_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'median'), axis=1)\n",
    "    dataset['6mt_var_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'var'), axis=1)\n",
    "#     dataset['6mt_std_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'std'), axis=1)\n",
    "#     dataset['6mt_sum_pop'] = dataset.apply(lambda row: tongji(row, 6, 'pop', 'sum'), axis=1)\n",
    "    # 4个月\n",
    "    dataset['4mt_mean_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'mean'), axis=1)\n",
    "    dataset['4mt_max_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'max'), axis=1)\n",
    "    dataset['4mt_min_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'min'), axis=1)\n",
    "    dataset['4mt_median_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'median'), axis=1)\n",
    "    dataset['4mt_var_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'var'), axis=1)\n",
    "#     dataset['4mt_std_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'std'), axis=1)\n",
    "#     dataset['4mt_sum_sale'] = dataset.apply(lambda row: tongji(row, 4, 'sale', 'sum'), axis=1)\n",
    "    \n",
    "    dataset['4mt_mean_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'mean'), axis=1)\n",
    "    dataset['4mt_max_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'max'), axis=1)\n",
    "    dataset['4mt_min_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'min'), axis=1)\n",
    "    dataset['4mt_median_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'median'), axis=1)\n",
    "    dataset['4mt_var_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'var'), axis=1)\n",
    "#     dataset['4mt_std_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'std'), axis=1)\n",
    "#     dataset['4mt_sum_pop'] = dataset.apply(lambda row: tongji(row, 4, 'pop', 'sum'), axis=1)\n",
    "    # 3个月 \n",
    "    dataset['3mt_mean_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'mean'), axis=1)\n",
    "    dataset['3mt_max_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'max'), axis=1)\n",
    "    dataset['3mt_min_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'min'), axis=1)\n",
    "    dataset['3mt_median_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'median'), axis=1)\n",
    "    dataset['3mt_var_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'var'), axis=1)\n",
    "#     dataset['3mt_std_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'std'), axis=1)\n",
    "#     dataset['3mt_sum_sale'] = dataset.apply(lambda row: tongji(row, 3, 'sale', 'sum'), axis=1)\n",
    "    \n",
    "    dataset['3mt_mean_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'mean'), axis=1)\n",
    "    dataset['3mt_max_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'max'), axis=1)\n",
    "    dataset['3mt_min_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'min'), axis=1)\n",
    "    dataset['3mt_median_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'median'), axis=1)\n",
    "    dataset['3mt_var_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'var'), axis=1)\n",
    "#     dataset['3mt_std_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'std'), axis=1)\n",
    "#     dataset['3mt_sum_pop'] = dataset.apply(lambda row: tongji(row, 3, 'pop', 'sum'), axis=1)\n",
    "    # 2个月\n",
    "    dataset['2mt_mean_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'mean'), axis=1)\n",
    "    dataset['2mt_max_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'max'), axis=1)\n",
    "    dataset['2mt_min_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'min'), axis=1)\n",
    "    dataset['2mt_median_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'median'), axis=1)\n",
    "    dataset['2mt_var_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'var'), axis=1)\n",
    "#     dataset['2mt_std_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'std'), axis=1)\n",
    "#     dataset['2mt_sum_sale'] = dataset.apply(lambda row: tongji(row, 2, 'sale', 'sum'), axis=1)\n",
    "    \n",
    "    dataset['2mt_mean_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'mean'), axis=1)\n",
    "    dataset['2mt_max_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'max'), axis=1)\n",
    "    dataset['2mt_min_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'min'), axis=1)\n",
    "    dataset['2mt_median_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'median'), axis=1)\n",
    "    dataset['2mt_var_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'var'), axis=1)\n",
    "#     dataset['2mt_std_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'std'), axis=1)\n",
    "#     dataset['2mt_sum_pop'] = dataset.apply(lambda row: tongji(row, 2, 'pop', 'sum'), axis=1)\n",
    "    \n",
    "    print('After data shape: ', dataset.shape)\n",
    "    print('='*30)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape:  (5808, 7)\n",
      "------------------------------\n",
      "After data shape:  (5808, 120)\n",
      "==============================\n",
      "Time cost(s):  271.5604248046875\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "train_feature = extract_feature(dataset_fusai, data_fusai)\n",
    "end_time=time.time()\n",
    "print('Time cost(s): ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['bodyType', 'model', 'province', 'regMonth', 'regYear']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    }
   ],
   "source": [
    "cate_feat = ['province', 'model', 'bodyType', 'regYear', 'regMonth'] #, 'bodyType'\n",
    "\n",
    "X_train = train_feature[train_feature['regMonth'].between(13, 24)]\n",
    "y_train = X_train[['salesVolume']]\n",
    "\n",
    "X_train.drop(['salesVolume', 'popularity'], axis=1, inplace=True)\n",
    "\n",
    "lgb_model = bulid_model(X_train, y_train, cate_feat=cate_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fusai['regMonth'] = test_fusai.apply(lambda row: row['regMonth'] + (row['regYear']-2016)*12, axis=1).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape:  (484, 6)\n",
      "------------------------------\n",
      "After data shape:  (484, 119)\n",
      "==============================\n",
      "Time cost(s):  23.95292901992798\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "test_feature_mt1 = extract_feature(test_fusai[test_fusai['regMonth']==25], data_fusai)\n",
    "end_time=time.time()\n",
    "print('Time cost(s): ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forecastVolum:\t 237.0024670938374\n",
      "Min forecastVolum:\t 1.6768337632384211\n",
      "Max forecastVolum:\t 2517.3386019047944\n",
      "Total forecastVolum:\t 114709.19407341728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "mytest1 = test_feature_mt1.copy()\n",
    "X_test1 = mytest1.drop('id', axis=1)\n",
    "y_test1 = mytest1[['id']]\n",
    "\n",
    "pred_log = lgb_model.predict(X_test1, num_iteration=lgb_model.best_iteration)\n",
    "test_feature_mt1['salesVolume'] = pred_log\n",
    "test_feature_mt1['salesVolume'] = test_feature_mt1['salesVolume'].apply(lambda x: x if x>0 else 0)\n",
    "# test_feature_mt1['salesVolume'] = np.round(test_feature_mt1['salesVolume']).astype(int)\n",
    "\n",
    "print('Average forecastVolum:\\t', np.expm1(test_feature_mt1['salesVolume']).mean())\n",
    "print('Min forecastVolum:\\t', np.expm1(test_feature_mt1['salesVolume']).min())\n",
    "print('Max forecastVolum:\\t', np.expm1(test_feature_mt1['salesVolume']).max())\n",
    "print('Total forecastVolum:\\t', np.expm1(test_feature_mt1['salesVolume']).sum())\n",
    "\n",
    "sub_test_feature_mt1 = test_feature_mt1[['province', 'model', 'bodyType', 'regYear', 'regMonth', 'salesVolume']]\n",
    "data_fusai = pd.concat([data_fusai, sub_test_feature_mt1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape:  (484, 6)\n",
      "------------------------------\n",
      "After data shape:  (484, 119)\n",
      "==============================\n",
      "Time cost(s):  23.926126956939697\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "test_feature_mt2 = extract_feature(test_fusai[test_fusai['regMonth']==26], data_fusai)\n",
    "end_time=time.time()\n",
    "print('Time cost(s): ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forecastVolum:\t 172.14275082230662\n",
      "Min forecastVolum:\t 1.5811361702900926\n",
      "Max forecastVolum:\t 1608.0346526752553\n",
      "Total forecastVolum:\t 83317.09139799635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "mytest2 = test_feature_mt2.copy()\n",
    "X_test2 = mytest2.drop('id', axis=1)\n",
    "y_test2 = mytest2[['id']]\n",
    "\n",
    "pred_log = lgb_model.predict(X_test2, num_iteration=lgb_model.best_iteration)\n",
    "test_feature_mt2['salesVolume'] = pred_log\n",
    "test_feature_mt2['salesVolume'] = test_feature_mt2['salesVolume'].apply(lambda x: x if x>0 else 0)\n",
    "# test_feature_mt2['salesVolume'] = np.round(test_feature_mt2['salesVolume']).astype(int)\n",
    "\n",
    "print('Average forecastVolum:\\t', np.expm1(test_feature_mt2['salesVolume']).mean())\n",
    "print('Min forecastVolum:\\t', np.expm1(test_feature_mt2['salesVolume']).min())\n",
    "print('Max forecastVolum:\\t', np.expm1(test_feature_mt2['salesVolume']).max())\n",
    "print('Total forecastVolum:\\t', np.expm1(test_feature_mt2['salesVolume']).sum())\n",
    "\n",
    "sub_test_feature_mt2 = test_feature_mt2[['province', 'model', 'bodyType', 'regYear', 'regMonth', 'salesVolume']]\n",
    "data_fusai = pd.concat([data_fusai, sub_test_feature_mt2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape:  (484, 6)\n",
      "------------------------------\n",
      "After data shape:  (484, 119)\n",
      "==============================\n",
      "Time cost(s):  23.93682050704956\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "test_feature_mt3 = extract_feature(test_fusai[test_fusai['regMonth']==27], data_fusai)\n",
    "end_time=time.time()\n",
    "print('Time cost(s): ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forecastVolum:\t 144.42664769803858\n",
      "Min forecastVolum:\t 1.2933912759284634\n",
      "Max forecastVolum:\t 1290.1166097232779\n",
      "Total forecastVolum:\t 69902.49748585065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "mytest3 = test_feature_mt3.copy()\n",
    "X_test3 = mytest3.drop('id', axis=1)\n",
    "y_test3 = mytest3[['id']]\n",
    "\n",
    "pred_log = lgb_model.predict(X_test3, num_iteration=lgb_model.best_iteration)\n",
    "test_feature_mt3['salesVolume'] = pred_log\n",
    "test_feature_mt3['salesVolume'] = test_feature_mt3['salesVolume'].apply(lambda x: x if x>0 else 0)\n",
    "# test_feature_mt3['salesVolume'] = np.round(test_feature_mt3['salesVolume']).astype(int)\n",
    "\n",
    "print('Average forecastVolum:\\t', np.expm1(test_feature_mt3['salesVolume']).mean())\n",
    "print('Min forecastVolum:\\t', np.expm1(test_feature_mt3['salesVolume']).min())\n",
    "print('Max forecastVolum:\\t', np.expm1(test_feature_mt3['salesVolume']).max())\n",
    "print('Total forecastVolum:\\t', np.expm1(test_feature_mt3['salesVolume']).sum())\n",
    "\n",
    "sub_test_feature_mt3 = test_feature_mt3[['province', 'model', 'bodyType', 'regYear', 'regMonth', 'salesVolume']]\n",
    "data_fusai = pd.concat([data_fusai, sub_test_feature_mt3], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data shape:  (484, 6)\n",
      "------------------------------\n",
      "After data shape:  (484, 119)\n",
      "==============================\n",
      "Time cost(s):  24.34208059310913\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "test_feature_mt4 = extract_feature(test_fusai[test_fusai['regMonth']==28], data_fusai)\n",
    "end_time=time.time()\n",
    "print('Time cost(s): ', end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average forecastVolum:\t 167.35664753832012\n",
      "Min forecastVolum:\t 1.8885755703214637\n",
      "Max forecastVolum:\t 1670.4455560616393\n",
      "Total forecastVolum:\t 81000.61740854697\n"
     ]
    }
   ],
   "source": [
    "mytest4 = test_feature_mt4.copy()\n",
    "X_test4 = mytest4.drop('id', axis=1)\n",
    "y_test4 = mytest4[['id']]\n",
    "\n",
    "pred_log = lgb_model.predict(X_test4, num_iteration=lgb_model.best_iteration)\n",
    "test_feature_mt4['salesVolume'] = pred_log\n",
    "test_feature_mt4['salesVolume'] = test_feature_mt4['salesVolume'].apply(lambda x: x if x>0 else 0)\n",
    "# test_feature_mt4['salesVolume'] = np.round(test_feature_mt4['salesVolume']).astype(int)\n",
    "\n",
    "print('Average forecastVolum:\\t', np.expm1(test_feature_mt4['salesVolume']).mean())\n",
    "print('Min forecastVolum:\\t', np.expm1(test_feature_mt4['salesVolume']).min())\n",
    "print('Max forecastVolum:\\t', np.expm1(test_feature_mt4['salesVolume']).max())\n",
    "print('Total forecastVolum:\\t', np.expm1(test_feature_mt4['salesVolume']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_pred = pd.concat([y_test1, y_test2, y_test3, y_test4])\n",
    "pred = pd.concat([test_feature_mt1['salesVolume'], test_feature_mt2['salesVolume'], test_feature_mt3['salesVolume'], test_feature_mt4['salesVolume']])\n",
    "\n",
    "lgb_pred['forecastVolum'] = pred\n",
    "lgb_pred['forecastVolum'] = np.expm1(lgb_pred['forecastVolum'])#expm1\n",
    "lgb_pred['forecastVolum'] = np.round(lgb_pred['forecastVolum']).astype(int)\n",
    "lgb_pred[['id', 'forecastVolum']].to_csv('./submit/lgb_ccy.csv', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.23347107438016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_pred.forecastVolum.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
