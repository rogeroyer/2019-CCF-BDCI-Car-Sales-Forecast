{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sub_zy_single_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.000703Z",
     "start_time": "2019-11-20T06:13:42.691206Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.088468Z",
     "start_time": "2019-11-20T06:13:44.002698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='./data/'   #复赛数据地址\n",
    "train_sale_path=path+'train_sales_data.csv'\n",
    "train_sale=pd.read_csv(train_sale_path)\n",
    "train_search_path=path+'train_search_data.csv'\n",
    "train_search=pd.read_csv(train_search_path)\n",
    "train_reply_path=path+'train_user_reply_data.csv'\n",
    "train_reply=pd.read_csv(train_reply_path)\n",
    "test_path=path+'evaluation_public.csv'\n",
    "test=pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.126368Z",
     "start_time": "2019-11-20T06:13:44.092458Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '../chusai/data/'   #初赛数据地址\n",
    "round1_data_path=path+'train_sales_data.csv'\n",
    "round1_data=pd.read_csv(round1_data_path)\n",
    "round1_model=list(round1_data['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.212138Z",
     "start_time": "2019-11-20T06:13:44.129359Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#合并训练集\n",
    "train_data=pd.merge(train_sale,train_search,how='left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "train_data=train_data.merge(train_reply,how='left',on=['model','regYear','regMonth'])\n",
    "\n",
    "#打标\n",
    "train_data['label']=train_data['salesVolume']\n",
    "del train_data['salesVolume'],test['forecastVolum']\n",
    "\n",
    "#编码\n",
    "transfer=train_data.drop_duplicates('model').set_index('model')['bodyType']\n",
    "train_data['bodyType'] = train_data['model'].map(transfer)\n",
    "test['bodyType']=test['model'].map(transfer)\n",
    "for i in ['bodyType', 'model']:\n",
    "    train_data[i+'or']=train_data[i]\n",
    "    test[i+'or']=test[i]\n",
    "    t=dict(zip(train_data[i].unique(), range(train_data[i].nunique())))\n",
    "    train_data[i] = train_data[i].map(t)\n",
    "    test[i]= test[i].map(t)\n",
    "train=train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.655951Z",
     "start_time": "2019-11-20T06:13:44.214132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'编码便于提取特征'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['mt'] = (train['regYear'] - 2016) * 12 + train['regMonth']\n",
    "test['mt']= (test['regYear'] - 2016) * 12 + test['regMonth']\n",
    "\n",
    "'编码便于提取特征'\n",
    "train['model_adcode'] = train['adcode'] + train['model']   \n",
    "test['model_adcode'] = test['adcode'] + test['model']\n",
    "\n",
    "train['adcode_bodyType'] = train['adcode']* 1000 + train['bodyType']   \n",
    "test['adcode_bodyType'] = test['adcode']* 1000 + test['bodyType']\n",
    "\n",
    "train['model_adcode_regMonth'] = train['model_adcode'] * 100 + train['regMonth']      #省份+车型+月份 编码\n",
    "test['model_adcode_regMonth']= test['model_adcode'] * 100 + test['regMonth']      #省份+车型+月份 编码\n",
    "\n",
    "train['model_regMonth'] = train['model'] * 1000 + train['regMonth']      #车型+月份 编码\n",
    "test['model_regMonth']= test['model'] * 1000 + test['regMonth']      #车型+月份 编码\n",
    "\n",
    "train['adcode_regMonth'] = train['adcode'] * 1000 + train['regMonth']      #省份+月份 编码\n",
    "test['adcode_regMonth']= test['adcode'] * 1000 + test['regMonth']      #省份+月份 编码\n",
    "\n",
    "train['bodyType_regMonth'] = train['bodyType'] * 1000 + train['regMonth']      #车身+月份 编码\n",
    "test['bodyType_regMonth']= test['bodyType'] * 1000 + test['regMonth']      #车身+月份 编码\n",
    "\n",
    "\n",
    "train['adcode_regMonth_bodyType'] = train['adcode_bodyType'] * 1000 + train['regMonth']      #省份+月份 编码\n",
    "test['adcode_regMonth_bodyType']= test['adcode_bodyType'] * 1000 + test['regMonth']      #省份+月份 编码\n",
    "\n",
    "train['model_adcode_mt'] = train['model_adcode'] * 100 + train['mt']      #省份+车型+月份 编码\n",
    "test['model_adcode_mt']= test['model_adcode'] * 100 + test['mt']      #省份+车型+月份 编码\n",
    "\n",
    "#季度\n",
    "def get_quar(x):\n",
    "    if x<=3:\n",
    "        return 1\n",
    "    elif x>3 and x<=6:\n",
    "        return 2 \n",
    "    elif x>6 and x<=9:\n",
    "        return 3\n",
    "    elif x>9:\n",
    "        return 12\n",
    "train['quarter']=train['regMonth'].apply(lambda x:get_quar(x))\n",
    "test['quarter']=test['regMonth'].apply(lambda x:get_quar(x))\n",
    "train['model_quarter'] = train['quarter']*10000 + train['model']   \n",
    "test['model_quarter'] = test['quarter'] *10000+ test['model']\n",
    "\n",
    "\n",
    "#前n月是哪一月\n",
    "def get_last_n_month(x,n):\n",
    "    if x<=n:\n",
    "        return 12+x-n\n",
    "    else:\n",
    "        return x-n\n",
    "\n",
    "for i in range(1,7):\n",
    "    train['last_month_{}'.format(i)]=train['regMonth'].apply(lambda x:get_last_n_month(x,i))\n",
    "    test['last_month_{}'.format(i)]=test['regMonth'].apply(lambda x:get_last_n_month(x,i))\n",
    "\n",
    "#后n月是哪一月\n",
    "def get_next_n_month(x,n):\n",
    "    if x>12-n:\n",
    "        return x-12+n\n",
    "    else:\n",
    "        return x+n\n",
    "\n",
    "for i in  range(1,7):\n",
    "    train['next_month_{}'.format(i)]=train['regMonth'].apply(lambda x:get_next_n_month(x,i))\n",
    "    test['next_month_{}'.format(i)]=test['regMonth'].apply(lambda x:get_next_n_month(x,i))\n",
    "\n",
    "\n",
    "#销售淡季与旺季\n",
    "def get_nice_month(x):\n",
    "    if x >=5 and x<=8:\n",
    "        return 0\n",
    "    if x>=10 or x==1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['nice_month']=train['regMonth'].apply(lambda x:get_nice_month(x))\n",
    "test['nice_month']=test['regMonth'].apply(lambda x:get_nice_month(x))\n",
    "\n",
    "def get_spring_counter(year,month):\n",
    "    if year==2016:\n",
    "        if month==2:\n",
    "            return 0\n",
    "        if month==1:\n",
    "            return -1\n",
    "        return month-2\n",
    "    if year==2017:\n",
    "        if month==1:\n",
    "            return 0\n",
    "        return month-1  \n",
    "    if year==2018:\n",
    "        if month==2:\n",
    "            return 0\n",
    "        if month==1:\n",
    "            return -1\n",
    "        return month-2  \n",
    "\n",
    "train['spring_counter']=list(map(lambda x,y:get_spring_counter(x,y),train['regYear'],train['regMonth']))\n",
    "test['spring_counter']=list(map(lambda x,y:get_spring_counter(x,y),test['regYear'],test['regMonth']))   \n",
    "\n",
    "\n",
    "def is_conf_year(x):\n",
    "    if x>=1 and x<=6:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['con_month']=train['regMonth'].apply(lambda x:is_conf_year(x))\n",
    "test['con_month']=test['regMonth'].apply(lambda x:is_conf_year(x))\n",
    "\n",
    "test['label']=np.nan   #预测结果\n",
    "train=pd.concat([train,test],axis=0)   \n",
    "\n",
    "cate_feat = ['adcode', 'bodyType', 'model', 'regMonth','spring_counter']+['next_month_{}'.format(i) for i in range(1,7)]+[\n",
    "    'last_month_{}'.format(i) for i in  range(1,7)]\n",
    "\n",
    "\n",
    "train_help=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.676894Z",
     "start_time": "2019-11-20T06:13:44.657946Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train[~train['modelor'].isin(round1_model)]\n",
    "test=test[~test['modelor'].isin(round1_model)]\n",
    "train_help=train_help[~train_help['modelor'].isin(round1_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.687865Z",
     "start_time": "2019-11-20T06:13:44.678889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13552, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.693849Z",
     "start_time": "2019-11-20T06:13:44.689860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1936, 36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:44.700830Z",
     "start_time": "2019-11-20T06:13:44.695844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13552, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_help.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:45.604413Z",
     "start_time": "2019-11-20T06:13:44.702825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'求线下结果'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'label 变换函数'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,num_feat,cate_feat,m_type='lgb',num=1000):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='rmse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2020,\n",
    "                                n_estimators=num, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "        \n",
    "        \n",
    "        f_importance = pd.DataFrame(columns=['f_name', 'importance'])\n",
    "        f_importance['importance'] = model.feature_importances_\n",
    "        f_importance['f_name'] =num_feat+cate_feat\n",
    "        f_importance['f_score'] = f_importance['importance'] / f_importance['importance'].sum()\n",
    "        f_importance.sort_values(['f_score'], ascending=False, inplace=True)\n",
    "        f_importance.drop(columns=['importance'], axis=1, inplace=True)\n",
    "#         f_importance.to_csv('im_lgb.csv',index=False)\n",
    "        print(f_importance)\n",
    "        \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=num, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)    \n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "'求线下结果'\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred: list,\n",
    "        label: [list, 'mean'],\n",
    "\n",
    "        }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "'label 变换函数'\n",
    "def confer_label(y):\n",
    "    return np.log(y+1)\n",
    "\n",
    "def confer_back_label(y):\n",
    "    return  np.power(np.exp(1),y)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1月模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:45.681207Z",
     "start_time": "2019-11-20T06:13:45.606408Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1月   验证集是9月'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1月   验证集是9月'\n",
    "num_feat=[]\n",
    "\n",
    "train_set=[]       #训练区间\n",
    "train_his_set=[]   #历史区间\n",
    "train_y_set=[]     #训练区间label\n",
    "\n",
    "\n",
    "gap=8\n",
    "shift=0\n",
    "for i in range(gap+shift+1,21):\n",
    "    train_his_set.append(train[(train['mt'].between(i-gap,i-1))])\n",
    "    train_set.append(train[(train['mt']==i)])\n",
    "    train_y_set.append(train[(train['mt']==i)][['label']])\n",
    "\n",
    "val_set=[]       #训练区间\n",
    "val_his_set=[]   #历史区间\n",
    "val_y_set=[]     #训练区间label\n",
    "\n",
    "for i in [21]:\n",
    "    val_his_set.append(train[(train['mt'].between(i-gap,i-1))])\n",
    "    val_set.append(train[(train['mt']==i)])\n",
    "    val_y_set.append(train[(train['mt']==i)][['label']])    \n",
    "\n",
    "test_his_set=[]    #test历史区间\n",
    "test_set=[]        #test训练区间\n",
    "for i in [25]:\n",
    "    test_his_set.append(train[(train['mt'].between(i-gap,i-1))])\n",
    "    test_set.append(train[(train['mt']==i)])\n",
    "    \n",
    "\n",
    "#train_y\n",
    "train_y=pd.concat([i for i in train_y_set],axis=0,sort=True)['label'].values\n",
    "train_y=confer_label(train_y)\n",
    "\n",
    "#val_y\n",
    "val_y=pd.concat([i for i in val_y_set],axis=0,sort=True)['label'].values\n",
    "val_y=confer_label(val_y)\n",
    "\n",
    "\n",
    "#val_preds\n",
    "val_pred_1=val_set[0][['model','label']]\n",
    "test_preds=test[['id','mt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1月特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:45.716114Z",
     "start_time": "2019-11-20T06:13:45.683202Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_his_features_1(his_or,data_or):\n",
    "    data=data_or.copy()\n",
    "    his=his_or.copy()\n",
    "    \n",
    "    prefiex='his_'\n",
    "    \n",
    "    his['label']=confer_label(his['label'].values)\n",
    "    \n",
    "    mt=list(his.mt.unique())\n",
    "    print(mt)\n",
    "    \n",
    "\n",
    "    sum_columns=['model_adcode']\n",
    "    \n",
    "    \n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    \n",
    "    '过去月的销量'   \n",
    "    for i in range(1,len(mt)+1):\n",
    "        data= get_last_key_sum(data,-i,'label') \n",
    "        \n",
    "    \n",
    "        \n",
    "    '过去月的涨幅'    \n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,1)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "    \n",
    "    '过去月的涨幅是正还是负'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去月的涨幅有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all'.format(key)+col]=all_tag_1\n",
    "        \n",
    "    '过去月的差分'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "            \n",
    "    '过去月差分的tag'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "                \n",
    "    '过去一阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff'.format(key)+col]=all_tag_1 \n",
    "                \n",
    "    '过去月的二阶差分'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_increased_diff'.format(key,i+1)+col].values  \n",
    "    '过去月二阶差分的tag'    \n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去二阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)-1):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff2'.format(key)+col]=all_tag_1 \n",
    "                    \n",
    "    \n",
    "\n",
    "\n",
    "    '销售最大最小'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        pre=prefiex+'sales_'+col\n",
    "        temp=his[[col,key]]\n",
    "        tmpdf = temp.groupby(col, as_index=False, sort=False)[key].agg(\n",
    "                        {pre+ '_mean': 'mean',\n",
    "                         pre + '_max': 'max', pre + '_min': 'min'})\n",
    "        data=data.merge(tmpdf,on=col,how='left')\n",
    "        \n",
    "    \n",
    "    '过去月的popu'\n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    for i in range(1,len(mt)+1):\n",
    "            data= get_last_key_sum(data,-i,'popularity')\n",
    "        \n",
    "\n",
    "    key='popularity'\n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    for i in range(1,len(mt)+1):\n",
    "            data= get_last_key_sum(data,-i,'popularity')\n",
    "    \n",
    "    '过去月的涨幅popu'\n",
    "    key='popularity'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,1)+col].values-data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "            \n",
    "    '过去月的涨幅是正还是负'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_tag_'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去月的差分popu'\n",
    "    key='popularity'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_gap'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i)+col].values-data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "    \n",
    "    \n",
    "    '上n月是增加还是减少'\n",
    "    key='popularity'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_gap_increased_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_gap'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "        \n",
    "        \n",
    "    '过去月的涨幅有多少为正的popularity'\n",
    "    key='popularity'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_gap_increased_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_last{}_gap_incread_tag1_all'.format(key,i)+col]=all_tag_1\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:48.041892Z",
     "start_time": "2019-11-20T06:13:45.724093Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 18, 19, 20, 22, 23, 21, 24]\n",
      "[17, 18, 19, 20, 22, 23, 21, 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "  8%|███▌                                       | 1/12 [00:00<00:01,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▊                                | 3/12 [00:00<00:01,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████▉                         | 5/12 [00:00<00:01,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████                  | 7/12 [00:01<00:00,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▋              | 8/12 [00:01<00:00,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████       | 10/12 [00:01<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 12/12 [00:01<00:00,  6.10it/s]\n",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  5.82it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 767.71it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 108)\n",
      "(5808, 108)\n",
      "(484, 108)\n"
     ]
    }
   ],
   "source": [
    "def get_all_features(test_his_set,test_set,train_his_set,train_set,val_his_set,val_set,get_his_features,num_feat_list,cate_feat):\n",
    "     \n",
    "    num_feat=num_feat_list.copy()\n",
    "    \n",
    "    test1_features1=get_his_features(test_his_set[0],test_set[0])\n",
    "    for col in list(test1_features1.columns):\n",
    "        if re.match('his', col)!=None:\n",
    "            num_feat.append(col)\n",
    "    \n",
    "    #test\n",
    "    test_features_set=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features_set.append(get_his_features(test_his_set[i],test_set[i])[num_feat])\n",
    "\n",
    "\n",
    "    #train\n",
    "    train_features_set=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features_set.append(get_his_features(train_his_set[i],train_set[i])[num_feat])\n",
    "\n",
    "    #val\n",
    "    val_features_set=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features_set.append(get_his_features(val_his_set[i],val_set[i])[num_feat])\n",
    "    \n",
    "    'cat features'\n",
    "    #test\n",
    "    test_features_set2=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features2=test_set[i][cate_feat]\n",
    "        test_features_set2.append(test_features2)\n",
    "\n",
    "    #train\n",
    "    train_features_set2=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features2=train_set[i][cate_feat]\n",
    "        train_features_set2.append(train_features2)    \n",
    "    \n",
    "    #val\n",
    "    val_features_set2=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features2=val_set[i][cate_feat]\n",
    "        val_features_set2.append(val_features2)    \n",
    "\n",
    "    'concat features'\n",
    "    #test\n",
    "    \n",
    "    test_features1=pd.concat([i for i in test_features_set],axis=0,sort=True)\n",
    "    test_features2=pd.concat([i for i in test_features_set2],axis=0,sort=True)\n",
    "    test_features1.index=np.arange(len(test_features1))\n",
    "    test_features2.index=np.arange(len(test_features2))\n",
    "    test1_x=pd.concat([test_features1,test_features2],axis=1)\n",
    "    print(test1_x.shape)\n",
    "    #train\n",
    "    train_features1=pd.concat([i for i in train_features_set],axis=0,sort=True)\n",
    "    train_features2=pd.concat([i for i in train_features_set2],axis=0,sort=True)\n",
    "    train_features1.index=np.arange(len(train_features1))\n",
    "    train_features2.index=np.arange(len(train_features2))\n",
    "    train_x=pd.concat([train_features1,train_features2],axis=1)[list(test1_x.columns)]\n",
    "    print(train_x.shape)\n",
    "    #val\n",
    "    val_features1 = pd.concat([i for i in val_features_set], axis=0, sort=True)\n",
    "    val_features2 = pd.concat([i for i in val_features_set2], axis=0, sort=True)\n",
    "    val_features1.index = np.arange(len(val_features1))\n",
    "    val_features2.index = np.arange(len(val_features2))\n",
    "    val_x = pd.concat([val_features1, val_features2], axis=1)[list(test1_x.columns)]\n",
    "    print(val_x.shape)\n",
    "    \n",
    "    \n",
    "    for i in cate_feat:\n",
    "        train_x[i]=train_x[i].astype('category')\n",
    "        test1_x[i]=test1_x[i].astype('category')\n",
    "        val_x[i]=val_x[i].astype('category')\n",
    "    \n",
    "    return train_x,val_x,test1_x,num_feat\n",
    "\n",
    "\n",
    "num_feat=[]\n",
    "cate_feat=cate_feat\n",
    "# cate_feat =cate_feat+ ['last_month_{}'.format(i) for i in range(1,7)]\n",
    "train_x,val_x,test_x,num_feat_this=get_all_features(test_his_set,test_set,train_his_set,\n",
    "                                              train_set,val_his_set,val_set,get_his_features_1,num_feat,cate_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1月模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:51.711077Z",
     "start_time": "2019-11-20T06:13:48.042889Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.187005\tvalid_1's rmse: 0.210199\n",
      "[200]\ttraining's rmse: 0.137451\tvalid_1's rmse: 0.211967\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's rmse: 0.175139\tvalid_1's rmse: 0.209826\n",
      "                                               f_name   f_score\n",
      "93                                              model  0.117241\n",
      "9           his_label_all_last2_increasedmodel_adcode  0.095402\n",
      "99                                       next_month_4  0.085632\n",
      "91                                             adcode  0.044540\n",
      "6                    his_label_all_last7_model_adcode  0.032471\n",
      "..                                                ...       ...\n",
      "33  his_label_all_last4_increased_diff_tagmodel_ad...  0.000000\n",
      "68     his_popularity_all_last7_increasedmodel_adcode  0.000000\n",
      "35  his_label_all_last6_increased_diff_tagmodel_ad...  0.000000\n",
      "73  his_popularity_all_last5_increased_tag_model_a...  0.000000\n",
      "82           his_popularity_all_last7_gapmodel_adcode  0.000000\n",
      "\n",
      "[108 rows x 2 columns]\n",
      "9月验证： 0.7781621846118538\n",
      "1月均值 250.87011725060526\n"
     ]
    }
   ],
   "source": [
    "lgb_model=get_model_type(train_x,train_y,val_x,val_y,num_feat_this,cate_feat)\n",
    "#线下分数\n",
    "val_pred_1['pred_label']= confer_back_label(lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration_))\n",
    "# np.power(np.exp(1),lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration_))-1\n",
    "train_help.loc[(train_help['mt']==21),'label']=val_pred_1['pred_label'].values    #方便验证\n",
    "print('9月验证：',score(val_pred_1))\n",
    "#预测一月\n",
    "test.loc[(test['mt']==25),'label'] =  confer_back_label(lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration_))\n",
    "# np.power(np.exp(1),lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration_))-1\n",
    "train.loc[(train['mt']==25),'label']=test.loc[(test['mt']==25),'label'].values\n",
    "print('1月均值',test.loc[(test['mt']==25),'label'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2月模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:51.797845Z",
     "start_time": "2019-11-20T06:13:51.714070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2月   验证集是10月'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2月   验证集是10月'\n",
    "num_feat=[]\n",
    "# cate_feat = ['adcode', 'bodyType', 'model', 'regMonth','spring_counter']\n",
    "\n",
    "train_set=[]       #训练区间\n",
    "train_his_set=[]   #历史区间\n",
    "train_y_set=[]     #训练区间label\n",
    "\n",
    "\n",
    "gap=8\n",
    "shift=0\n",
    "for i in range(gap+shift+1,21):\n",
    "    train_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    train_set.append(train[(train['mt']==i)])\n",
    "    train_y_set.append(train[(train['mt']==i)][['label']])\n",
    "\n",
    "val_set=[]       #训练区间\n",
    "val_his_set=[]   #历史区间\n",
    "val_y_set=[]     #训练区间label\n",
    "\n",
    "for i in [22]:\n",
    "    val_his_set.append(train_help[(train_help['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    val_set.append(train_help[(train_help['mt']==i)])\n",
    "    val_y_set.append(train_help[(train_help['mt']==i)][['label']])    \n",
    "\n",
    "test_his_set=[]    #test历史区间\n",
    "test_set=[]        #test训练区间\n",
    "for i in [26]:\n",
    "    test_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    test_set.append(train[(train['mt']==i)])\n",
    "    \n",
    "\n",
    "#train_y\n",
    "train_y=pd.concat([i for i in train_y_set],axis=0,sort=True)['label'].values\n",
    "train_y=confer_label(train_y)\n",
    "\n",
    "#val_y\n",
    "val_y=pd.concat([i for i in val_y_set],axis=0,sort=True)['label'].values\n",
    "val_y=confer_label(val_y)\n",
    "\n",
    "\n",
    "#val_preds\n",
    "val_pred_2=val_set[0][['model','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2月特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:51.826768Z",
     "start_time": "2019-11-20T06:13:51.801834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_his_features_1(his_or,data_or):\n",
    "    data=data_or.copy()\n",
    "    his=his_or.copy()\n",
    "    \n",
    "    prefiex='his_'\n",
    "    \n",
    "    his['label']=confer_label(his['label'].values)\n",
    "    \n",
    "    mt=list(his.mt.unique())\n",
    "    print(mt)\n",
    "    \n",
    "\n",
    "    sum_columns=['model_adcode']\n",
    "    \n",
    "    \n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    '过去月的销量'   \n",
    "    for i in range(1,len(mt)+1):\n",
    "        data= get_last_key_sum(data,-i,'label') \n",
    "        \n",
    "    '过去月的涨幅'    \n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,1)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "    \n",
    "    '过去月的涨幅是正还是负'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去月的涨幅有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all'.format(key)+col]=all_tag_1\n",
    "        \n",
    "    '过去月的差分'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "            \n",
    "    '过去月差分的tag'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "                \n",
    "    '过去一阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff'.format(key)+col]=all_tag_1 \n",
    "                \n",
    "    '过去月的二阶差分'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_increased_diff'.format(key,i+1)+col].values  \n",
    "    '过去月二阶差分的tag'    \n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去二阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)-1):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff2'.format(key)+col]=all_tag_1 \n",
    "                    \n",
    "    \n",
    "\n",
    "\n",
    "    '销售最大最小'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        pre=prefiex+'sales_'+col\n",
    "        temp=his[[col,key]]\n",
    "        tmpdf = temp.groupby(col, as_index=False, sort=False)[key].agg(\n",
    "                        {pre+ '_mean': 'mean',\n",
    "                         pre + '_max': 'max', pre + '_min': 'min'})\n",
    "        data=data.merge(tmpdf,on=col,how='left')\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:13:53.658867Z",
     "start_time": "2019-11-20T06:13:51.830757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "  0%|                                                   | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 19, 20, 22, 23, 21, 24, 25]\n",
      "[18, 19, 20, 22, 23, 21, 24, 25]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                   | 2/12 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 6/12 [00:00<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▋              | 8/12 [00:00<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 12/12 [00:00<00:00, 12.80it/s]\n",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 12.80it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 768.38it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 71)\n",
      "(5808, 71)\n",
      "(484, 71)\n"
     ]
    }
   ],
   "source": [
    "def get_all_features(test_his_set,test_set,train_his_set,train_set,val_his_set,val_set,get_his_features,num_feat_list,cate_feat):\n",
    "     \n",
    "    num_feat=num_feat_list.copy()\n",
    "    \n",
    "    test1_features1=get_his_features(test_his_set[0],test_set[0])\n",
    "    for col in list(test1_features1.columns):\n",
    "        if re.match('his', col)!=None:\n",
    "            num_feat.append(col)\n",
    "    \n",
    "    #test\n",
    "    test_features_set=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features_set.append(get_his_features(test_his_set[i],test_set[i])[num_feat])\n",
    "\n",
    "\n",
    "    #train\n",
    "    train_features_set=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features_set.append(get_his_features(train_his_set[i],train_set[i])[num_feat])\n",
    "\n",
    "    #val\n",
    "    val_features_set=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features_set.append(get_his_features(val_his_set[i],val_set[i])[num_feat])\n",
    "    \n",
    "    'cat features'\n",
    "    #test\n",
    "    test_features_set2=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features2=test_set[i][cate_feat]\n",
    "        test_features_set2.append(test_features2)\n",
    "\n",
    "    #train\n",
    "    train_features_set2=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features2=train_set[i][cate_feat]\n",
    "        train_features_set2.append(train_features2)    \n",
    "    \n",
    "    #val\n",
    "    val_features_set2=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features2=val_set[i][cate_feat]\n",
    "        val_features_set2.append(val_features2)    \n",
    "\n",
    "    'concat features'\n",
    "    #test\n",
    "    \n",
    "    test_features1=pd.concat([i for i in test_features_set],axis=0,sort=True)\n",
    "    test_features2=pd.concat([i for i in test_features_set2],axis=0,sort=True)\n",
    "    test_features1.index=np.arange(len(test_features1))\n",
    "    test_features2.index=np.arange(len(test_features2))\n",
    "    test1_x=pd.concat([test_features1,test_features2],axis=1)\n",
    "    print(test1_x.shape)\n",
    "    #train\n",
    "    train_features1=pd.concat([i for i in train_features_set],axis=0,sort=True)\n",
    "    train_features2=pd.concat([i for i in train_features_set2],axis=0,sort=True)\n",
    "    train_features1.index=np.arange(len(train_features1))\n",
    "    train_features2.index=np.arange(len(train_features2))\n",
    "    train_x=pd.concat([train_features1,train_features2],axis=1)[list(test1_x.columns)]\n",
    "    print(train_x.shape)\n",
    "    #val\n",
    "    val_features1 = pd.concat([i for i in val_features_set], axis=0, sort=True)\n",
    "    val_features2 = pd.concat([i for i in val_features_set2], axis=0, sort=True)\n",
    "    val_features1.index = np.arange(len(val_features1))\n",
    "    val_features2.index = np.arange(len(val_features2))\n",
    "    val_x = pd.concat([val_features1, val_features2], axis=1)[list(test1_x.columns)]\n",
    "    print(val_x.shape)\n",
    "    \n",
    "    \n",
    "    for i in cate_feat:\n",
    "        train_x[i]=train_x[i].astype('category')\n",
    "        test1_x[i]=test1_x[i].astype('category')\n",
    "        val_x[i]=val_x[i].astype('category')\n",
    "    \n",
    "    return train_x,val_x,test1_x,num_feat\n",
    "\n",
    "\n",
    "num_feat=[]\n",
    "cate_feat=cate_feat\n",
    "# cate_feat =cate_feat+ ['last_month_{}'.format(i) for i in range(1,7)]\n",
    "train_x,val_x,test_x,num_feat_this=get_all_features(test_his_set,test_set,train_his_set,\n",
    "                                              train_set,val_his_set,val_set,get_his_features_1,num_feat,cate_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2月模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:02.211987Z",
     "start_time": "2019-11-20T06:13:53.666846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.193324\tvalid_1's rmse: 0.285221\n",
      "[200]\ttraining's rmse: 0.143139\tvalid_1's rmse: 0.28506\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's rmse: 0.166127\tvalid_1's rmse: 0.283635\n",
      "                                               f_name   f_score\n",
      "56                                              model  0.112057\n",
      "9           his_label_all_last2_increasedmodel_adcode  0.099054\n",
      "62                                       next_month_4  0.095272\n",
      "54                                             adcode  0.058392\n",
      "6                    his_label_all_last7_model_adcode  0.041135\n",
      "..                                                ...       ...\n",
      "39    his_label_all_last2_increased_diff2model_adcode  0.000000\n",
      "14          his_label_all_last7_increasedmodel_adcode  0.000000\n",
      "18      his_label_all_last4_increased_tagmodel_adcode  0.000000\n",
      "47  his_label_all_last4_increased_diff_tag2model_a...  0.000000\n",
      "35  his_label_all_last6_increased_diff_tagmodel_ad...  0.000000\n",
      "\n",
      "[71 rows x 2 columns]\n",
      "10月验证： 0.7032391799078438\n",
      "2月均值 161.1804842865657\n"
     ]
    }
   ],
   "source": [
    "lgb_model=get_model_type(train_x,train_y,val_x,val_y,num_feat_this,cate_feat)\n",
    "#线下分数\n",
    "val_pred_2['pred_label']=confer_back_label(lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration_))\n",
    "train_help.loc[(train_help['mt']==22),'label']=val_pred_2['pred_label'].values  #方便验证\n",
    "print('10月验证：',score(val_pred_2))\n",
    "#预测一月\n",
    "test.loc[(test['mt']==26),'label'] =  confer_back_label(lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration_))\n",
    "train.loc[(train['mt']==26),'label']=test.loc[(test['mt']==26),'label'].values\n",
    "print('2月均值',test.loc[(test['mt']==26),'label'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3月模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:02.328675Z",
     "start_time": "2019-11-20T06:14:02.213982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3月   验证集是11月'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'3月   验证集是11月'\n",
    "num_feat=[]\n",
    "# cate_feat = ['adcode', 'bodyType', 'model', 'regMonth','spring_counter']\n",
    "\n",
    "train_set=[]       #训练区间\n",
    "train_his_set=[]   #历史区间\n",
    "train_y_set=[]     #训练区间label\n",
    "\n",
    "\n",
    "gap=8\n",
    "shift=0\n",
    "for i in range(gap+shift+1,21):\n",
    "    train_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    train_set.append(train[(train['mt']==i)])\n",
    "    train_y_set.append(train[(train['mt']==i)][['label']])\n",
    "\n",
    "val_set=[]       #训练区间\n",
    "val_his_set=[]   #历史区间\n",
    "val_y_set=[]     #训练区间label\n",
    "\n",
    "for i in [23]:\n",
    "    val_his_set.append(train_help[(train_help['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    val_set.append(train_help[(train_help['mt']==i)])\n",
    "    val_y_set.append(train_help[(train_help['mt']==i)][['label']])    \n",
    "\n",
    "test_his_set=[]    #test历史区间\n",
    "test_set=[]        #test训练区间\n",
    "for i in [27]:\n",
    "    test_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    test_set.append(train[(train['mt']==i)])\n",
    "    \n",
    "\n",
    "#train_y\n",
    "train_y=pd.concat([i for i in train_y_set],axis=0,sort=True)['label'].values\n",
    "train_y=confer_label(train_y)\n",
    "\n",
    "#val_y\n",
    "val_y=pd.concat([i for i in val_y_set],axis=0,sort=True)['label'].values\n",
    "val_y=confer_label(val_y)\n",
    "\n",
    "\n",
    "#val_preds\n",
    "val_pred_3=val_set[0][['model','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3月特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:02.359593Z",
     "start_time": "2019-11-20T06:14:02.331667Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_his_features_1(his_or,data_or):\n",
    "    data=data_or.copy()\n",
    "    his=his_or.copy()\n",
    "    \n",
    "    prefiex='his_'\n",
    "    \n",
    "    his['label']=confer_label(his['label'].values)\n",
    "    \n",
    "    mt=list(his.mt.unique())\n",
    "    print(mt)\n",
    "    \n",
    "\n",
    "    sum_columns=['model_adcode']\n",
    "    \n",
    "    \n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    '过去月的销量'   \n",
    "    for i in range(1,len(mt)+1):\n",
    "        data= get_last_key_sum(data,-i,'label') \n",
    "        \n",
    "    '过去月的涨幅'    \n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,1)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "    \n",
    "    '过去月的涨幅是正还是负'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去月的涨幅有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all'.format(key)+col]=all_tag_1\n",
    "        \n",
    "    '过去月的差分'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "            \n",
    "    '过去月差分的tag'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "                \n",
    "    '过去一阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff'.format(key)+col]=all_tag_1 \n",
    "                \n",
    "    '过去月的二阶差分'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_increased_diff'.format(key,i+1)+col].values  \n",
    "    '过去月二阶差分的tag'    \n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去二阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)-1):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff2'.format(key)+col]=all_tag_1 \n",
    "                    \n",
    "    \n",
    "\n",
    "\n",
    "    '销售最大最小'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        pre=prefiex+'sales_'+col\n",
    "        temp=his[[col,key]]\n",
    "        tmpdf = temp.groupby(col, as_index=False, sort=False)[key].agg(\n",
    "                        {pre+ '_mean': 'mean',\n",
    "                         pre + '_max': 'max', pre + '_min': 'min'})\n",
    "        data=data.merge(tmpdf,on=col,how='left')  \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:03.967609Z",
     "start_time": "2019-11-20T06:14:02.361588Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "  0%|                                                   | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 20, 22, 23, 21, 24, 25, 26]\n",
      "[19, 20, 22, 23, 21, 24, 25, 26]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                   | 2/12 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 6/12 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▋              | 8/12 [00:00<00:00, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 12/12 [00:00<00:00, 12.80it/s]\n",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[15, 16, 17, 18, 19, 20, 22, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 10.67it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████| 12/12 [00:00<?, ?it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 71)\n",
      "(5808, 71)\n",
      "(484, 71)\n"
     ]
    }
   ],
   "source": [
    "def get_all_features(test_his_set,test_set,train_his_set,train_set,val_his_set,val_set,get_his_features,num_feat_list,cate_feat):\n",
    "     \n",
    "    num_feat=num_feat_list.copy()\n",
    "    \n",
    "    test1_features1=get_his_features(test_his_set[0],test_set[0])\n",
    "    for col in list(test1_features1.columns):\n",
    "        if re.match('his', col)!=None:\n",
    "            num_feat.append(col)\n",
    "    \n",
    "    #test\n",
    "    test_features_set=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features_set.append(get_his_features(test_his_set[i],test_set[i])[num_feat])\n",
    "\n",
    "\n",
    "    #train\n",
    "    train_features_set=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features_set.append(get_his_features(train_his_set[i],train_set[i])[num_feat])\n",
    "\n",
    "    #val\n",
    "    val_features_set=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features_set.append(get_his_features(val_his_set[i],val_set[i])[num_feat])\n",
    "    \n",
    "    'cat features'\n",
    "    #test\n",
    "    test_features_set2=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features2=test_set[i][cate_feat]\n",
    "        test_features_set2.append(test_features2)\n",
    "\n",
    "    #train\n",
    "    train_features_set2=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features2=train_set[i][cate_feat]\n",
    "        train_features_set2.append(train_features2)    \n",
    "    \n",
    "    #val\n",
    "    val_features_set2=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features2=val_set[i][cate_feat]\n",
    "        val_features_set2.append(val_features2)    \n",
    "\n",
    "    'concat features'\n",
    "    #test\n",
    "    \n",
    "    test_features1=pd.concat([i for i in test_features_set],axis=0,sort=True)\n",
    "    test_features2=pd.concat([i for i in test_features_set2],axis=0,sort=True)\n",
    "    test_features1.index=np.arange(len(test_features1))\n",
    "    test_features2.index=np.arange(len(test_features2))\n",
    "    test1_x=pd.concat([test_features1,test_features2],axis=1)\n",
    "    print(test1_x.shape)\n",
    "    #train\n",
    "    train_features1=pd.concat([i for i in train_features_set],axis=0,sort=True)\n",
    "    train_features2=pd.concat([i for i in train_features_set2],axis=0,sort=True)\n",
    "    train_features1.index=np.arange(len(train_features1))\n",
    "    train_features2.index=np.arange(len(train_features2))\n",
    "    train_x=pd.concat([train_features1,train_features2],axis=1)[list(test1_x.columns)]\n",
    "    print(train_x.shape)\n",
    "    #val\n",
    "    val_features1 = pd.concat([i for i in val_features_set], axis=0, sort=True)\n",
    "    val_features2 = pd.concat([i for i in val_features_set2], axis=0, sort=True)\n",
    "    val_features1.index = np.arange(len(val_features1))\n",
    "    val_features2.index = np.arange(len(val_features2))\n",
    "    val_x = pd.concat([val_features1, val_features2], axis=1)[list(test1_x.columns)]\n",
    "    print(val_x.shape)\n",
    "    \n",
    "    \n",
    "    for i in cate_feat:\n",
    "        train_x[i]=train_x[i].astype('category')\n",
    "        test1_x[i]=test1_x[i].astype('category')\n",
    "        val_x[i]=val_x[i].astype('category')\n",
    "    \n",
    "    return train_x,val_x,test1_x,num_feat\n",
    "\n",
    "\n",
    "num_feat=[]\n",
    "cate_feat=cate_feat\n",
    "# cate_feat =cate_feat+ ['last_month_{}'.format(i) for i in range(1,7)]\n",
    "train_x,val_x,test_x,num_feat_this=get_all_features(test_his_set,test_set,train_his_set,\n",
    "                                              train_set,val_his_set,val_set,get_his_features_1,num_feat,cate_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3月模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:08.583262Z",
     "start_time": "2019-11-20T06:14:03.969604Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.193324\tvalid_1's rmse: 0.396262\n",
      "[200]\ttraining's rmse: 0.143139\tvalid_1's rmse: 0.391723\n",
      "[300]\ttraining's rmse: 0.117744\tvalid_1's rmse: 0.390038\n",
      "[400]\ttraining's rmse: 0.0987606\tvalid_1's rmse: 0.388725\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's rmse: 0.100056\tvalid_1's rmse: 0.388281\n",
      "                                             f_name   f_score\n",
      "62                                     next_month_4  0.073129\n",
      "56                                            model  0.064116\n",
      "54                                           adcode  0.059269\n",
      "9         his_label_all_last2_increasedmodel_adcode  0.048129\n",
      "6                  his_label_all_last7_model_adcode  0.036905\n",
      "..                                              ...       ...\n",
      "64                                     next_month_6  0.000000\n",
      "63                                     next_month_5  0.000000\n",
      "39  his_label_all_last2_increased_diff2model_adcode  0.000000\n",
      "7                  his_label_all_last8_model_adcode  0.000000\n",
      "61                                     next_month_3  0.000000\n",
      "\n",
      "[71 rows x 2 columns]\n",
      "11月验证： 0.5499419615873804\n",
      "3月均值 232.30300950599465\n"
     ]
    }
   ],
   "source": [
    "lgb_model=get_model_type(train_x,train_y,val_x,val_y,num_feat_this,cate_feat)\n",
    "#线下分数\n",
    "val_pred_3['pred_label']=confer_back_label(lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration_))\n",
    "train_help.loc[(train_help['mt']==23),'label']=val_pred_3['pred_label'].values  #方便验证\n",
    "print('11月验证：',score(val_pred_3))\n",
    "#预测一月\n",
    "test.loc[(test['mt']==27),'label'] = confer_back_label(lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration_))\n",
    "train.loc[(train['mt']==27),'label']=test.loc[(test['mt']==27),'label'].values\n",
    "print('3月均值',test.loc[(test['mt']==27),'label'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4月模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:08.667038Z",
     "start_time": "2019-11-20T06:14:08.584260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1月'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1月'\n",
    "num_feat=[]\n",
    "# cate_feat = ['adcode', 'bodyType', 'model', 'regMonth','spring_counter']\n",
    "\n",
    "train_set=[]       #训练区间\n",
    "train_his_set=[]   #历史区间\n",
    "train_y_set=[]     #训练区间label\n",
    "\n",
    "\n",
    "gap=8\n",
    "shift=0\n",
    "for i in range(gap+shift+1,21):\n",
    "    train_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    train_set.append(train[(train['mt']==i)])\n",
    "    train_y_set.append(train[(train['mt']==i)][['label']])\n",
    "\n",
    "val_set=[]       #训练区间\n",
    "val_his_set=[]   #历史区间\n",
    "val_y_set=[]     #训练区间label\n",
    "\n",
    "for i in [24]:\n",
    "    val_his_set.append(train_help[(train_help['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    val_set.append(train_help[(train_help['mt']==i)])\n",
    "    val_y_set.append(train_help[(train_help['mt']==i)][['label']])    \n",
    "\n",
    "test_his_set=[]    #test历史区间\n",
    "test_set=[]        #test训练区间\n",
    "for i in [28]:\n",
    "    test_his_set.append(train[(train['mt'].between(i-gap-shift,i-shift-1))])\n",
    "    test_set.append(train[(train['mt']==i)])\n",
    "    \n",
    "\n",
    "#train_y\n",
    "train_y=pd.concat([i for i in train_y_set],axis=0,sort=True)['label'].values\n",
    "train_y=confer_label(train_y)\n",
    "\n",
    "#val_y\n",
    "val_y=pd.concat([i for i in val_y_set],axis=0,sort=True)['label'].values\n",
    "val_y=confer_label(val_y)\n",
    "\n",
    "\n",
    "#val_preds\n",
    "val_pred_4=val_set[0][['model','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4月特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:08.692969Z",
     "start_time": "2019-11-20T06:14:08.669033Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_his_features_1(his_or,data_or):\n",
    "    data=data_or.copy()\n",
    "    his=his_or.copy()\n",
    "    \n",
    "    prefiex='his_'\n",
    "    \n",
    "    his['label']=confer_label(his['label'].values)\n",
    "    \n",
    "    mt=list(his.mt.unique())\n",
    "    print(mt)\n",
    "    \n",
    "\n",
    "    sum_columns=['model_adcode']\n",
    "    \n",
    "    \n",
    "    def get_last_key_sum(data_,i,key):\n",
    "        data=data_.copy()\n",
    "        temp=his[his['mt']==mt[i]]\n",
    "        for col in sum_columns:\n",
    "            f=temp[[col,key]].groupby(col)[key].agg('sum')\n",
    "            data[prefiex+'{}_all_last{}_'.format(key,-i)+col]=data[col].map(f)\n",
    "        return data\n",
    "    \n",
    "    '过去月的销量'   \n",
    "    for i in range(1,len(mt)+1):\n",
    "        data= get_last_key_sum(data,-i,'label') \n",
    "        \n",
    "    '过去月的涨幅'    \n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,1)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "    \n",
    "    '过去月的涨幅是正还是负'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去月的涨幅有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all'.format(key)+col]=all_tag_1\n",
    "        \n",
    "    '过去月的差分'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_'.format(key,i+1)+col].values\n",
    "            \n",
    "    '过去月差分的tag'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "                \n",
    "    '过去一阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff'.format(key)+col]=all_tag_1 \n",
    "                \n",
    "    '过去月的二阶差分'\n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "            data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col]=data[\n",
    "                prefiex+'{}_all_last{}_increased_diff'.format(key,i)+col].values-data[\n",
    "                            prefiex+'{}_all_last{}_increased_diff'.format(key,i+1)+col].values  \n",
    "    '过去月二阶差分的tag'    \n",
    "    for col in sum_columns:\n",
    "        for i in range(1,len(mt)-1):\n",
    "              data[prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col]=data[prefiex+'{}_all_last{}_increased_diff2'.format(key,i)+col].apply(\n",
    "          lambda x: 1 if x>0 else 0)\n",
    "    \n",
    "    '过去二阶差分有多少为正的'\n",
    "    for col in sum_columns:\n",
    "        columns=[]\n",
    "        for i in range(1,len(mt)-1):\n",
    "            columns.append(prefiex+'{}_all_last{}_increased_diff_tag2'.format(key,i)+col)\n",
    "        all_tag_1=np.sum(data[columns].values,axis=1)\n",
    "        data[prefiex+'{}_all_increased_tag_1all_diff2'.format(key)+col]=all_tag_1 \n",
    "                    \n",
    "    \n",
    "\n",
    "\n",
    "    '销售最大最小'\n",
    "    key='label'\n",
    "    for col in sum_columns:\n",
    "        pre=prefiex+'sales_'+col\n",
    "        temp=his[[col,key]]\n",
    "        tmpdf = temp.groupby(col, as_index=False, sort=False)[key].agg(\n",
    "                        {pre+ '_mean': 'mean',\n",
    "                         pre + '_max': 'max', pre + '_min': 'min'})\n",
    "        data=data.merge(tmpdf,on=col,how='left')  \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:10.022412Z",
     "start_time": "2019-11-20T06:14:08.694964Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 12.80it/s]\n",
      "  0%|                                                   | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 22, 23, 21, 24, 25, 26, 27]\n",
      "[20, 22, 23, 21, 24, 25, 26, 27]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████▏                                   | 2/12 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[3, 4, 5, 6, 7, 8, 9, 10]\n",
      "[4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 6/12 [00:00<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████▋              | 8/12 [00:00<00:00, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 12/12 [00:00<00:00, 13.02it/s]\n",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[16, 17, 18, 19, 20, 22, 23, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 10.67it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 767.75it/s]\n",
      "100%|████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 71)\n",
      "(5808, 71)\n",
      "(484, 71)\n"
     ]
    }
   ],
   "source": [
    "def get_all_features(test_his_set,test_set,train_his_set,train_set,val_his_set,val_set,get_his_features,num_feat_list,cate_feat):\n",
    "     \n",
    "    num_feat=num_feat_list.copy()\n",
    "    \n",
    "    test1_features1=get_his_features(test_his_set[0],test_set[0])\n",
    "    for col in list(test1_features1.columns):\n",
    "        if re.match('his', col)!=None:\n",
    "            num_feat.append(col)\n",
    "    \n",
    "    #test\n",
    "    test_features_set=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features_set.append(get_his_features(test_his_set[i],test_set[i])[num_feat])\n",
    "\n",
    "\n",
    "    #train\n",
    "    train_features_set=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features_set.append(get_his_features(train_his_set[i],train_set[i])[num_feat])\n",
    "\n",
    "    #val\n",
    "    val_features_set=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features_set.append(get_his_features(val_his_set[i],val_set[i])[num_feat])\n",
    "    \n",
    "    'cat features'\n",
    "    #test\n",
    "    test_features_set2=[]\n",
    "    for i in tqdm(range(0,len(test_set))):\n",
    "        test_features2=test_set[i][cate_feat]\n",
    "        test_features_set2.append(test_features2)\n",
    "\n",
    "    #train\n",
    "    train_features_set2=[]\n",
    "    for i in tqdm(range(0,len(train_set))):\n",
    "        train_features2=train_set[i][cate_feat]\n",
    "        train_features_set2.append(train_features2)    \n",
    "    \n",
    "    #val\n",
    "    val_features_set2=[]\n",
    "    for i in tqdm(range(0,len(val_set))):\n",
    "        val_features2=val_set[i][cate_feat]\n",
    "        val_features_set2.append(val_features2)    \n",
    "\n",
    "    'concat features'\n",
    "    #test\n",
    "    \n",
    "    test_features1=pd.concat([i for i in test_features_set],axis=0,sort=True)\n",
    "    test_features2=pd.concat([i for i in test_features_set2],axis=0,sort=True)\n",
    "    test_features1.index=np.arange(len(test_features1))\n",
    "    test_features2.index=np.arange(len(test_features2))\n",
    "    test1_x=pd.concat([test_features1,test_features2],axis=1)\n",
    "    print(test1_x.shape)\n",
    "    #train\n",
    "    train_features1=pd.concat([i for i in train_features_set],axis=0,sort=True)\n",
    "    train_features2=pd.concat([i for i in train_features_set2],axis=0,sort=True)\n",
    "    train_features1.index=np.arange(len(train_features1))\n",
    "    train_features2.index=np.arange(len(train_features2))\n",
    "    train_x=pd.concat([train_features1,train_features2],axis=1)[list(test1_x.columns)]\n",
    "    print(train_x.shape)\n",
    "    #val\n",
    "    val_features1 = pd.concat([i for i in val_features_set], axis=0, sort=True)\n",
    "    val_features2 = pd.concat([i for i in val_features_set2], axis=0, sort=True)\n",
    "    val_features1.index = np.arange(len(val_features1))\n",
    "    val_features2.index = np.arange(len(val_features2))\n",
    "    val_x = pd.concat([val_features1, val_features2], axis=1)[list(test1_x.columns)]\n",
    "    print(val_x.shape)\n",
    "    \n",
    "    \n",
    "    for i in cate_feat:\n",
    "        train_x[i]=train_x[i].astype('category')\n",
    "        test1_x[i]=test1_x[i].astype('category')\n",
    "        val_x[i]=val_x[i].astype('category')\n",
    "    \n",
    "    return train_x,val_x,test1_x,num_feat\n",
    "\n",
    "\n",
    "num_feat=[]\n",
    "cate_feat=cate_feat\n",
    "# cate_feat =cate_feat+ ['last_month_{}'.format(i) for i in range(1,7)]\n",
    "train_x,val_x,test_x,num_feat_this=get_all_features(test_his_set,test_set,train_his_set,\n",
    "                                              train_set,val_his_set,val_set,get_his_features_1,num_feat,cate_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4月模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.222202Z",
     "start_time": "2019-11-20T06:14:10.023409Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 0.193324\tvalid_1's rmse: 0.401503\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's rmse: 0.24824\tvalid_1's rmse: 0.382878\n",
      "                                               f_name   f_score\n",
      "9           his_label_all_last2_increasedmodel_adcode  0.224848\n",
      "56                                              model  0.146667\n",
      "62                                       next_month_4  0.070303\n",
      "16      his_label_all_last2_increased_tagmodel_adcode  0.054545\n",
      "23     his_label_all_last1_increased_diffmodel_adcode  0.039394\n",
      "..                                                ...       ...\n",
      "14          his_label_all_last7_increasedmodel_adcode  0.000000\n",
      "7                    his_label_all_last8_model_adcode  0.000000\n",
      "5                    his_label_all_last6_model_adcode  0.000000\n",
      "4                    his_label_all_last5_model_adcode  0.000000\n",
      "35  his_label_all_last6_increased_diff_tagmodel_ad...  0.000000\n",
      "\n",
      "[71 rows x 2 columns]\n",
      "12月验证： 0.5531870590390626\n",
      "4月均值 206.57001477884594\n"
     ]
    }
   ],
   "source": [
    "lgb_model=get_model_type(train_x,train_y,val_x,val_y,num_feat_this,cate_feat)\n",
    "#线下分数\n",
    "val_pred_4['pred_label']=confer_back_label(lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration_))\n",
    "train_help.loc[(train_help['mt']==24),'label']=val_pred_4['pred_label'].values  #方便验证\n",
    "print('12月验证：',score(val_pred_4))\n",
    "#预测一月\n",
    "test.loc[(test['mt']==28),'label'] =  confer_back_label(lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration_))\n",
    "train.loc[(train['mt']==28),'label']=test.loc[(test['mt']==28),'label'].values\n",
    "print('4月均值',test.loc[(test['mt']==28),'label'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线下和保存线上 (20个车型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.241152Z",
     "start_time": "2019-11-20T06:14:11.224197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1月均值 250.87011725060526\n",
      "4月均值 161.1804842865657\n",
      "4月均值 232.30300950599465\n",
      "4月均值 206.57001477884594\n"
     ]
    }
   ],
   "source": [
    "print('1月均值',test.loc[(test['mt']==25),'label'].mean())\n",
    "print('4月均值',test.loc[(test['mt']==26),'label'].mean())\n",
    "print('4月均值',test.loc[(test['mt']==27),'label'].mean())\n",
    "print('4月均值',test.loc[(test['mt']==28),'label'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.289024Z",
     "start_time": "2019-11-20T06:14:11.243147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[(test['mt']==27),'label'] =  test.loc[(test['mt']==27),'label'].values*0.6\n",
    "test.loc[(test['mt']==28),'label'] =  test.loc[(test['mt']==28),'label'].values*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.311963Z",
     "start_time": "2019-11-20T06:14:11.292016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1月均值 250.87011725060526\n",
      "2月均值 161.1804842865657\n",
      "3月均值 139.38180570359688\n",
      "4月均值 165.2560118230765\n"
     ]
    }
   ],
   "source": [
    "print('1月均值',test.loc[(test['mt']==25),'label'].mean())\n",
    "print('2月均值',test.loc[(test['mt']==26),'label'].mean())\n",
    "print('3月均值',test.loc[(test['mt']==27),'label'].mean())\n",
    "print('4月均值',test.loc[(test['mt']==28),'label'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.340885Z",
     "start_time": "2019-11-20T06:14:11.313958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score 0.6060447430593856\n"
     ]
    }
   ],
   "source": [
    "#线下分数\n",
    "val=pd.concat([val_pred_1,val_pred_2,val_pred_3,val_pred_4],axis=0,sort=True)\n",
    "print('val score',score(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T06:14:11.377797Z",
     "start_time": "2019-11-20T06:14:11.341883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1936, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=test[['id','label']]\n",
    "sub.columns=['id','forecastVolum']\n",
    "sub['forecastVolum']=sub['forecastVolum'].apply(lambda x:int(x))\n",
    "sub.shape\n",
    "sub[['id','forecastVolum']].to_csv('./submit/sub_zy.csv',index=False)   #我的结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.926px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
